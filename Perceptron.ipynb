{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52dc07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron en pytorch (en utilisant juste les tenseurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64415ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, numpy, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90978f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "nb_epochs = 10\n",
    "eta = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e27811b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "((data_train, label_train), (data_test, label_test)) = torch.load(gzip.open('mnist.pkl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3e29b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tensuer avec size Size([63000, 784]) c'est-a-dire : le nombre de lignes du tenseur est 63000 et le nombre de colonnes du tenseur est 784\n",
    "# il y a 63 000 images dans l'ensemble de données et chaque image fait 28x28 pixels = 784\n",
    "#data_train.shape ==> torch.Size([63000, 784])\n",
    "#tensuer avec size Size([7000, 784]) c'est-a-dire : le nombre de lignes du tenseur est 7000 et le nombre de colonnes du tenseur est 784\n",
    "# il y a 7000 images dans l'ensemble de données et chaque image fait 28x28 pixels = 784\n",
    "#data_test.shape ==> torch.Size([7000, 784]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b106834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crée une tenseur W de poids avec la taille (784,10) pour connecter les 784 pixels d'entrée d'une image du dataset MNIST à 10 sorties (chiffres de 0 à 9).\n",
    "w = torch.empty((data_train.shape[1], label_train.shape[1]), dtype=torch.float)\n",
    "# crée un vecteur de biais b de forme (1,10) pour ajuster les prévisions de chaque classe (0 à 9 pour le dataset MNIST)\n",
    "b = torch.empty((1, label_train.shape[1]), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "777bef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#w.shape ==> torch.size([784, 10]) \n",
    "#b.shape ==> torch.size([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05946c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.6027e-04, -2.7672e-04, -7.2359e-04,  2.2989e-04,  7.1416e-04,\n",
       "         -3.9948e-05,  3.2837e-04, -8.7702e-04,  5.8902e-04,  1.6347e-04]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialiser les tenseurs de poids w et le vecteur de biais avec des valeurs aléatoires choisies de manière uniforme entre -0.001 et 0.001\n",
    "torch.nn.init.uniform_(w, -0.001, 0.001)\n",
    "torch.nn.init.uniform_(b, -0.001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "667a8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crée un tableau indices contenant tous les entiers de 0 à 62999.\n",
    "indices = numpy.arange(len(data_train))\n",
    "#Cette boucle externe permet de parcourir toutes les données d'entraînement plusieurs fois\n",
    "for n in range(nb_epochs):\n",
    "    #Cette ligne mélange les indices des données d'entraînement de manière aléatoire avant chaque époque\n",
    "    numpy.random.shuffle(indices)\n",
    "    #Cette boucle interne divise l'ensemble de données en lots de taille batch_size=5. À chaque itération, i prend une valeur correspondant à l'index de début d'un batch.\n",
    "    for i in range(0, len(data_train), batch_size):\n",
    "        #Récupère les images du lot (batch) en sélectionnant batch_size=5 données à partir de l'index i\n",
    "        #torch.Size([5, 784]) il y a 5 images et chaque image fait 28x28 pixels = 784\n",
    "        x = data_train[indices[i:i+batch_size]]\n",
    "        #Calcule la sortie du modèle (prédiction) pour les entrées x\n",
    "        #torch.mm(x, w) : Calcule le produit matriciel entre x et w (les poids du modèle).\n",
    "        #Ajoute le biais à chaque prédiction\n",
    "        #torch.Size([5, 10]) y de taille [5, 10] contient les prédictions du modèle pour 5 image\n",
    "        y = torch.mm(x, w) + b \n",
    "        #torch.Size([5, 10]) Extrait les labels pour un groupe de 5 images d'entraînement\n",
    "        t = label_train[indices[i:i+batch_size]] \n",
    "        #Calcul du gradient et t représente les labels réels pour le batch actuel, et y représente les prédictions du modèle pour ce même batch.\n",
    "        #torch.Size([5, 10])\n",
    "        grad = (t - y)\n",
    "        #Mise à jour des poids : x est de forme [5,784] Alors : la forme de x.T est [784,5] et grad est de forme [5,10]\n",
    "        #Cette opération est un produit matriciel entre la transposée des entrées x.T et le gradient grad. Cela permet de calculer la modification des poids à appliquer.\n",
    "        w += eta * torch.mm(x.T, grad)\n",
    "        #Mise à jour du biais : \n",
    "        #grad.sum(axis=0) ==> calcule la somme des gradients pour chaque classe (torch.Size([10]))\n",
    "        #Le biais est ajusté pour chaque classe afin de réduire l'erreur globale du modèle\n",
    "        b += eta * grad.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a8ed4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8596])\n"
     ]
    }
   ],
   "source": [
    "acc = 0.\n",
    "for i in range(len(data_test)):\n",
    "    #torch.Size([1, 784]) il y a une image et chaque image fait 28x28 pixels = 784\n",
    "    x = data_test[i:i+1]\n",
    "    #torch.mm(x, w) : Calcule le produit matriciel entre x et w (les poids du modèle).\n",
    "    #Ajoute le biais à chaque prédiction\n",
    "    #y de taille [1, 10] contient les prédictions du modèle pour une image\n",
    "    y = torch.mm(x, w) + b\n",
    "    #torch.Size([1, 10]) Extrait les labels pour une image d'entraînement\n",
    "    t = label_test[i:i+1]\n",
    "    #Cette partie compare les classes prédictes par le modèle aux classes réelles.\n",
    "    #Cette partie incrémente la variable acc avec le nombre de prédictions correctes dans le batch\n",
    "    acc += torch.argmax(y, 1) == torch.argmax(t, 1)\n",
    "print(acc / len(data_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16401214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron en pytorch (en utilisant les outils de Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d72b89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # nombre de données lues à chaque fois\n",
    "nb_epochs = 10 # nombre de fois que la base de données sera lue\n",
    "eta = 0.00001 # taux d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ecd827ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on lit les données\n",
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('mnist.pkl.gz'))\n",
    "# on crée les lecteurs de données\n",
    "train_dataset = torch.utils.data.TensorDataset(data_train,label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test,label_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfb0625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on initialise le modèle et ses poids\n",
    "model = torch.nn.Linear(data_train.shape[1],label_train.shape[1])\n",
    "torch.nn.init.uniform_(model.weight,-0.001,0.001)\n",
    "# on initiliase l'optimiseur\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.SGD(model.parameters(), lr=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ccb3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(nb_epochs):\n",
    "    # on lit toutes les données d'apprentissage\n",
    "    for x,t in train_loader:\n",
    "        # on calcule la sortie du modèle\n",
    "        y = model(x)\n",
    "        # on met à jour les poids\n",
    "        loss = loss_func(t,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f3109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8569])\n"
     ]
    }
   ],
   "source": [
    "# test du modèle (on évalue la progression pendant l'apprentissage)\n",
    "acc = 0.\n",
    "# on lit toutes les donnéees de test\n",
    "for x,t in test_loader:\n",
    "    # on calcule la sortie du modèle\n",
    "    y = model(x)\n",
    "    # on regarde si la sortie est correcte\n",
    "    acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "# on affiche le pourcentage de bonnes réponses\n",
    "print(acc/data_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ea45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
